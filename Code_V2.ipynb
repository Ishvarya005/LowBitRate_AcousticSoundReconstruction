{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11215972,"sourceType":"datasetVersion","datasetId":7003943},{"sourceId":11235808,"sourceType":"datasetVersion","datasetId":7019108},{"sourceId":11251198,"sourceType":"datasetVersion","datasetId":7030802},{"sourceId":11281817,"sourceType":"datasetVersion","datasetId":7053505},{"sourceId":11281843,"sourceType":"datasetVersion","datasetId":7053525},{"sourceId":11297811,"sourceType":"datasetVersion","datasetId":7064817},{"sourceId":321549,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":271034,"modelId":292022}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Step 0: Import Dataset and check the files in each folder","metadata":{}},{"cell_type":"code","source":"import os\n\nDATASETS_PATH = \"/kaggle/input\"\n\nprint(\"üìÇ Available datasets in /kaggle/input:\")\nprint(os.listdir(DATASETS_PATH))\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-06T14:49:13.430173Z","iopub.execute_input":"2025-04-06T14:49:13.430543Z","iopub.status.idle":"2025-04-06T14:49:13.437460Z","shell.execute_reply.started":"2025-04-06T14:49:13.430517Z","shell.execute_reply":"2025-04-06T14:49:13.435974Z"}},"outputs":[{"name":"stdout","text":"üìÇ Available datasets in /kaggle/input:\n['testfiles-demucs', 'musan-data', 'demucs_epoch_8', 'compressedtest5', 'reconstructed-demucs', 'compressed-data', 'testonyoutubetedtalk']\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"DATA_PATH = \"/kaggle/input/musan-data/musan\"  # Adjust if needed\n\nif os.path.exists(DATA_PATH):\n    print(\"‚úÖ Dataset found! Listing contents:\")\n    print(os.listdir(DATA_PATH))\nelse:\n    print(\"‚ùå Dataset not found! Double-check the path.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T14:49:15.766534Z","iopub.execute_input":"2025-04-06T14:49:15.766908Z","iopub.status.idle":"2025-04-06T14:49:15.776054Z","shell.execute_reply.started":"2025-04-06T14:49:15.766879Z","shell.execute_reply":"2025-04-06T14:49:15.774695Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Dataset found! Listing contents:\n['noise', 'README', 'music', 'speech']\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"for category in [\"music\", \"noise\", \"speech\"]:\n    folder_path = os.path.join(DATA_PATH, category)\n    if os.path.exists(folder_path):\n        files = os.listdir(folder_path)[:5]  # Show first 5 files\n        print(f\"\\nüìÇ {category} - {len(os.listdir(folder_path))} files\")\n        print(files)\n    else:\n        print(f\"‚ö†Ô∏è Folder '{category}' not found!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T14:49:18.224033Z","iopub.execute_input":"2025-04-06T14:49:18.224385Z","iopub.status.idle":"2025-04-06T14:49:18.237417Z","shell.execute_reply.started":"2025-04-06T14:49:18.224348Z","shell.execute_reply":"2025-04-06T14:49:18.236341Z"}},"outputs":[{"name":"stdout","text":"\nüìÇ music - 6 files\n['README', 'jamendo', 'hd-classical', 'fma', 'fma-western-art']\n\nüìÇ noise - 3 files\n['README', 'sound-bible', 'free-sound']\n\nüìÇ speech - 3 files\n['README', 'librivox', 'us-gov']\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"for category in [\"music\", \"noise\", \"speech\"]:\n    folder_path = os.path.join(DATA_PATH, category)\n\n    for subfolder in os.listdir(folder_path):\n        subfolder_path = os.path.join(folder_path, subfolder)\n        \n        if os.path.isdir(subfolder_path):  # Ensure it's a directory\n            audio_files = [f for f in os.listdir(subfolder_path) if f.endswith(('.wav', '.mp3'))][:5]\n            print(f\"\\nüìÇ {category}/{subfolder} - {len(os.listdir(subfolder_path))} files\")\n            print(audio_files)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T14:49:20.795253Z","iopub.execute_input":"2025-04-06T14:49:20.795662Z","iopub.status.idle":"2025-04-06T14:49:20.826518Z","shell.execute_reply.started":"2025-04-06T14:49:20.795629Z","shell.execute_reply":"2025-04-06T14:49:20.825375Z"}},"outputs":[{"name":"stdout","text":"\nüìÇ music/jamendo - 219 files\n['music-jamendo-0044.wav', 'music-jamendo-0208.wav', 'music-jamendo-0093.wav', 'music-jamendo-0131.wav', 'music-jamendo-0132.wav']\n\nüìÇ music/hd-classical - 77 files\n['music-hd-0073.wav', 'music-hd-0063.wav', 'music-hd-0040.wav', 'music-hd-0056.wav', 'music-hd-0015.wav']\n\nüìÇ music/fma - 130 files\n['music-fma-0039.wav', 'music-fma-0087.wav', 'music-fma-0037.wav', 'music-fma-0109.wav', 'music-fma-0068.wav']\n\nüìÇ music/fma-western-art - 95 files\n['music-fma-wa-0032.wav', 'music-fma-wa-0051.wav', 'music-fma-wa-0028.wav', 'music-fma-wa-0009.wav', 'music-fma-wa-0088.wav']\n\nüìÇ music/rfm - 150 files\n['music-rfm-0044.wav', 'music-rfm-0014.wav', 'music-rfm-0022.wav', 'music-rfm-0003.wav', 'music-rfm-0125.wav']\n\nüìÇ noise/sound-bible - 88 files\n['noise-sound-bible-0017.wav', 'noise-sound-bible-0023.wav', 'noise-sound-bible-0019.wav', 'noise-sound-bible-0021.wav', 'noise-sound-bible-0057.wav']\n\nüìÇ noise/free-sound - 845 files\n['noise-free-sound-0626.wav', 'noise-free-sound-0162.wav', 'noise-free-sound-0773.wav', 'noise-free-sound-0177.wav', 'noise-free-sound-0161.wav']\n\nüìÇ speech/librivox - 175 files\n['speech-librivox-0014.wav', 'speech-librivox-0134.wav', 'speech-librivox-0129.wav', 'speech-librivox-0066.wav', 'speech-librivox-0003.wav']\n\nüìÇ speech/us-gov - 254 files\n['speech-us-gov-0134.wav', 'speech-us-gov-0159.wav', 'speech-us-gov-0162.wav', 'speech-us-gov-0063.wav', 'speech-us-gov-0189.wav']\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"# Step 1: Preprocessing: Checking all files to know its sample rates and channel","metadata":{}},{"cell_type":"markdown","source":"> Librosa : Librosa is a Python package designed for music and audio analysis. It provides tools for extracting meaningful features from audio signals, such as spectrograms and MFCCs (Mel-frequency cepstral coefficients), which \nare crucial for tasks like music information retrieval and sound classification","metadata":{}},{"cell_type":"markdown","source":"## Exception Handling (i)","metadata":{}},{"cell_type":"markdown","source":"> The code below also handles exception to prevent the program from crashing if a corrupt file is encountered.\n> There could be some files that could be corrupt or in a format that librosa can‚Äôt read, have unexpected metadata etc.\n> Even 1 bad file could crash the entire loop,thus with this block - it skips the problematic file and prints a message showing the file path and the error","metadata":{}},{"cell_type":"code","source":"# tells how many files at each sample rate and tells how many mono and stereo files\n\nimport os\nimport librosa\n\nDATA_PATH = \"/kaggle/input/musan-data/musan/\"  # Update this with your actual dataset path\n\n# Function to check sample rate & channels\ndef check_audio_properties(root_folder):\n    sample_rates = {}\n    channel_counts = {}\n\n    for root, _, files in os.walk(root_folder):\n        for file in files:\n            if file.endswith(\".wav\"):  # Only process WAV files\n                file_path = os.path.join(root, file)\n                \n                try:\n                    audio, sr = librosa.load(file_path, sr=None, mono=False)  # Load in original format\n                    #this returns a numpy array of audio samples and sr is the sampling rates\n                    #in the parameters its set to None so that librosa doesnt change the sr or mono\n                    \n                    channels = 1 if len(audio.shape) == 1 else 2  # Determine mono or stereo\n                    #audio is either of shape (T,) or (2,T) so based on the dimension its classified as mono or stereo\n                    \n                    # Store results\n                    if sr not in sample_rates:\n                        sample_rates[sr] = 0\n                    sample_rates[sr] += 1\n                    #returns a dictionary of the sampling rates and their corresponding counts\n\n                    if channels not in channel_counts:\n                        channel_counts[channels] = 0\n                    channel_counts[channels] += 1\n\n                except Exception as e:\n                    print(f\"Error processing {file_path}: {e}\")\n\n    return sample_rates, channel_counts\n    \n\n# Run check\nsample_rates, channel_counts = check_audio_properties(DATA_PATH)\n\n# Print results\nprint(\"üéµ Sample Rate Distribution:\", sample_rates)\nprint(\"üéß Channel Distribution (1=Mono, 2=Stereo):\", channel_counts)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T14:44:23.215355Z","iopub.execute_input":"2025-04-06T14:44:23.215751Z","iopub.status.idle":"2025-04-06T14:47:47.408395Z","shell.execute_reply.started":"2025-04-06T14:44:23.215706Z","shell.execute_reply":"2025-04-06T14:47:47.407207Z"}},"outputs":[{"name":"stdout","text":"üéµ Sample Rate Distribution: {16000: 2016}\nüéß Channel Distribution (1=Mono, 2=Stereo): {1: 2016}\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"## Exception Handling (ii) \n> ffprobe returns the bit rate info as JSON objects\n> The exception handling prevents crashes from: Malformed JSON output, Missing keys like \"streams\" or \"bit_rate\", Empty or unexpected structures\n> Keeps the script robust and fault-tolerant\n\n","metadata":{}},{"cell_type":"code","source":"# Analyzing the bit-rate used across 5 random files across each of the 5 categories\n\nimport os\nimport subprocess #to run shell commands ( use it to call ffprobe)\nimport json\nfrom collections import defaultdict\n\n# Define dataset path\nDATA_PATH = \"/kaggle/input/musan-data/musan\"\nCATEGORIES = [\"music\", \"noise\", \"speech\"]\nfile_count = defaultdict(int)\nMAX_FILES = 5  # Limit to 5 files per category\n\n# Function to extract bit rate\ndef get_bit_rate(file_path):\n    cmd = f\"ffprobe -i '{file_path}' -show_entries stream=bit_rate -of json -v quiet\"\n    #The list of individual media streams (e.g., audio, video, subtitles) inside a\n    #multimedia file as reported by ffprobe\n    #for a video file, streams might include video stream, audio, subtitle stream etc\n    result = subprocess.run(cmd, shell=True, capture_output=True, text=True)\n    #capture_output=True: stores stdout and stderr ; text=True: return output as strings\n    \n    try:\n        #Parse the JSON output into a Python dictionary\n        #Return the bit rate from the first stream (since its a .wav file, it most def. has only 1 stream - audio)\n        #if it exists\n        data = json.loads(result.stdout)  # Convert JSON string to dictionary\n        return data[\"streams\"][0][\"bit_rate\"] if \"streams\" in data and data[\"streams\"] else \"N/A\"\n    #If any of the following errors occur:\n\n#JSONDecodeError: if output is not valid JSON\n#KeyError: if \"streams\" or \"bit_rate\" is missing  #IndexError: if \"streams\" list is empty #Then return \"N/A\" as a fallback value instead of crashing\n    except (json.JSONDecodeError, KeyError, IndexError):\n        return \"N/A\"\n\n# Process only 5 files from each category\nfor root, _, files in os.walk(DATA_PATH):\n    for file in files:\n        if file.endswith(\".wav\"):\n            file_path = os.path.join(root, file)\n\n            # Identify category from folder structure\n            for category in CATEGORIES:\n                if f\"/{category}/\" in file_path and file_count[category] < MAX_FILES:\n                    bit_rate = get_bit_rate(file_path)\n                    print(f\"üîç {category.upper()} | {file}: {bit_rate} bps\")\n\n                    file_count[category] += 1\n                    break  # Move to next file\n\n        if all(count >= MAX_FILES for count in file_count.values()):\n            break\n\nprint(\"\\n‚úÖ Bit rate extraction complete for 5 files per category!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T14:51:21.852708Z","iopub.execute_input":"2025-04-06T14:51:21.854034Z","iopub.status.idle":"2025-04-06T14:51:26.162414Z","shell.execute_reply.started":"2025-04-06T14:51:21.853985Z","shell.execute_reply":"2025-04-06T14:51:26.160994Z"}},"outputs":[{"name":"stdout","text":"üîç NOISE | noise-sound-bible-0017.wav: 256000 bps\nüîç NOISE | noise-sound-bible-0023.wav: 256000 bps\nüîç NOISE | noise-sound-bible-0019.wav: 256000 bps\nüîç NOISE | noise-sound-bible-0021.wav: 256000 bps\nüîç NOISE | noise-sound-bible-0057.wav: 256000 bps\nüîç MUSIC | music-jamendo-0044.wav: 256000 bps\nüîç MUSIC | music-jamendo-0208.wav: 256000 bps\nüîç MUSIC | music-jamendo-0093.wav: 256000 bps\nüîç MUSIC | music-jamendo-0131.wav: 256000 bps\nüîç MUSIC | music-jamendo-0132.wav: 256000 bps\nüîç SPEECH | speech-librivox-0014.wav: 256000 bps\nüîç SPEECH | speech-librivox-0134.wav: 256000 bps\nüîç SPEECH | speech-librivox-0129.wav: 256000 bps\nüîç SPEECH | speech-librivox-0066.wav: 256000 bps\nüîç SPEECH | speech-librivox-0003.wav: 256000 bps\n\n‚úÖ Bit rate extraction complete for 5 files per category!\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"## Since all files have the same sample rate of 16kHz and all are mono, we dont have to perform the explicit standardization","metadata":{}},{"cell_type":"markdown","source":"## Since all files show a high bit-rate of 256kbps, we compress to different low bit-rates\n","metadata":{}},{"cell_type":"markdown","source":"# Step 2: Compression at different bit rates for all files\n","metadata":{}},{"cell_type":"code","source":"!apt-get install -y ffmpeg\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T15:49:26.129214Z","iopub.execute_input":"2025-04-06T15:49:26.129739Z","iopub.status.idle":"2025-04-06T15:49:30.187464Z","shell.execute_reply.started":"2025-04-06T15:49:26.129704Z","shell.execute_reply":"2025-04-06T15:49:30.186013Z"}},"outputs":[{"name":"stdout","text":"The history saving thread hit an unexpected error (OperationalError('attempt to write a readonly database')).History will not be written to the database.\nReading package lists... Done\nBuilding dependency tree... Done\nReading state information... Done\nffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n0 upgraded, 0 newly installed, 0 to remove and 129 not upgraded.\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"> ffmpeg - It is a free and open source software project that offers many tools for video and audio processing. It's designed to run on a command line interface, and has many different libraries and programs to manipulate and handle video files.","metadata":{}},{"cell_type":"code","source":"import os\nimport subprocess\nimport shutil\n\n# Paths\nDATA_PATH = \"/kaggle/input/musan-data/musan/music\"\nOUTPUT_PATH = \"/kaggle/working/compressed_music_sample\"\n\n# Bitrates for music compression\nBITRATES = {\"16kbps\": \"16000\", \"32kbps\": \"32000\", \"64kbps\": \"64000\"}\n\n# Ensure output directory exists\nos.makedirs(OUTPUT_PATH, exist_ok=True)\n\n# Get a subfolder inside 'music'\nmusic_subfolders = [f.path for f in os.scandir(DATA_PATH) if f.is_dir()]\nif not music_subfolders:\n    print(\"‚ùå No subfolders found in music.\")\nelse:\n    music_folder = music_subfolders[0]  # Choose the first subfolder\n    music_files = [f for f in os.listdir(music_folder) if f.endswith(\".wav\")][:5]  # Pick 5 files\n\n    # Compress 5 files\n    for file in music_files:\n        input_file = os.path.join(music_folder, file)\n        for bitrate_name, bitrate_value in BITRATES.items():\n            output_dir = os.path.join(OUTPUT_PATH, f\"compressed_{bitrate_name}\")\n            os.makedirs(output_dir, exist_ok=True)\n            output_file = os.path.join(output_dir, file.replace(\".wav\", \".opus\"))\n            \n            # Compress using ffmpeg\n            cmd = f\"ffmpeg -i '{input_file}' -c:a libopus -b:a {bitrate_value} '{output_file}' -y\"\n            subprocess.run(cmd, shell=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n\n    print(\"‚úÖ Compression complete! Files saved in:\", OUTPUT_PATH)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import shutil\n\n# Path to save the zip file\nZIP_PATH = \"/kaggle/working/compressed_music_sample.zip\"\n\n# Create zip archive\nshutil.make_archive(ZIP_PATH.replace(\".zip\", \"\"), 'zip', \"/kaggle/working/compressed_music_sample\")\n\nprint(f\"‚úÖ Zip file created: {ZIP_PATH}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T05:31:19.238504Z","iopub.execute_input":"2025-04-01T05:31:19.238898Z","iopub.status.idle":"2025-04-01T05:31:20.097951Z","shell.execute_reply.started":"2025-04-01T05:31:19.238869Z","shell.execute_reply":"2025-04-01T05:31:20.096974Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Step 3.1: Compressing the speech folder applying 3 bit rates corresponding to speech data\n","metadata":{}},{"cell_type":"markdown","source":">### Here the compressing code is shown for speech data, similarly compression is been carried out for music files (5 subfolders - fma, fma-western-art, hd-classical, jamendo, rfm) by taking the first 100 files in each subfolder and for noise data too (by taking first 100 files from the 2 subfolders - free-sound and sound-bible)","metadata":{}},{"cell_type":"code","source":"import os\nimport subprocess\nimport shutil\n\n# Paths\nDATA_PATH = \"/kaggle/input/musan-data/musan/speech\"\nOUTPUT_PATH = \"/kaggle/working/compressed_speech\"\n\n# Bitrates for speech compression\nBITRATES = {\n    \"3kbps\": \"3000\",\n    \"6kbps\": \"6000\",\n    \"12kbps\": \"12000\"\n}\n\n# Create output directory if not exists\nos.makedirs(OUTPUT_PATH, exist_ok=True)\n\n# Function to compress a single file\ndef compress_audio(input_file, output_file, bitrate):\n    cmd = f\"ffmpeg -i '{input_file}' -c:a libopus -b:a {bitrate} '{output_file}' -y\"\n    subprocess.run(cmd, shell=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n\n# Resume check: Load last processed file if exists\nresume_file = \"/kaggle/working/speech_last_processed.txt\"\nlast_processed = None\nif os.path.exists(resume_file):\n    with open(resume_file, \"r\") as f:\n        last_processed = f.read().strip()\n\n# Process files\nprocessed_count = 0\nresume_found = last_processed is None  # If no resume file, start immediately\n\nfor root, _, files in os.walk(DATA_PATH):\n    # Only process files in 'librivox' folder\n    if 'librivox' in root:\n        for file in sorted(files):  # Sorting ensures consistent processing order\n            if file.endswith(\".wav\"):\n                input_file = os.path.join(root, file)\n                relative_path = os.path.relpath(root, DATA_PATH)  # Maintain hierarchy\n                \n                if not resume_found:\n                    if input_file == last_processed:\n                        resume_found = True  # Resume processing from the next file\n                    continue\n                \n                # Apply compression for each bitrate\n                for bitrate_label, bitrate_value in BITRATES.items():\n                    output_dir = os.path.join(OUTPUT_PATH, f\"compressed_{bitrate_label}\", relative_path)\n                    os.makedirs(output_dir, exist_ok=True)  # Create directories if missing\n                    \n                    output_file = os.path.join(output_dir, file.replace(\".wav\", \".opus\"))\n                    compress_audio(input_file, output_file, bitrate_value)\n\n                processed_count += 1\n                \n                # Save progress every 50 files\n                if processed_count % 50 == 0:\n                    with open(resume_file, \"w\") as f:\n                        f.write(input_file)\n                    \n                    # Zip and upload files every 50 processed\n                    zip_path = \"/kaggle/working/compressed_speech.zip\"\n                    shutil.make_archive(zip_path.replace(\".zip\", \"\"), 'zip', OUTPUT_PATH)\n                    print(\"‚úÖ 50 files compressed & backup saved!\")\n\nprint(\"‚úÖ Speech compression complete!\")\n\n# Final dataset backup\nfinal_zip_path = \"/kaggle/working/compressed_speech_final.zip\"\nshutil.make_archive(final_zip_path.replace(\".zip\", \"\"), 'zip', OUTPUT_PATH)\nprint(f\"‚úÖ Final backup saved at: {final_zip_path}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T16:17:58.867129Z","iopub.execute_input":"2025-04-01T16:17:58.867544Z","iopub.status.idle":"2025-04-01T17:10:57.920795Z","shell.execute_reply.started":"2025-04-01T16:17:58.867517Z","shell.execute_reply":"2025-04-01T17:10:57.919880Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Compressed all 175 files from LibriVox and first 150 files from US-GOV folder ","metadata":{}},{"cell_type":"markdown","source":"# Step 3.2: Compressing speech subfolder : us-gov \n","metadata":{}},{"cell_type":"code","source":"import os\nimport subprocess\nimport shutil\n\n# Paths\nDATA_PATH = \"/kaggle/input/musan-data/musan/speech/us-gov\"\nOUTPUT_PATH = \"/kaggle/working/usgov_compressed_speech\"\n\n# Bitrates for speech compression\nBITRATES = {\n    \"3kbps\": \"3000\",\n    \"6kbps\": \"6000\",\n    \"12kbps\": \"12000\"\n}\n\n# Create output directory if not exists\nos.makedirs(OUTPUT_PATH, exist_ok=True)\n\n# Function to compress a single file\ndef compress_audio(input_file, output_file, bitrate):\n    cmd = f\"ffmpeg -i '{input_file}' -c:a libopus -b:a {bitrate} '{output_file}' -y\"\n    subprocess.run(cmd, shell=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n\n# Resume check: Load last processed file if exists\nresume_file = \"/kaggle/working/usgov_last_processed.txt\"\nlast_processed = None\nif os.path.exists(resume_file):\n    with open(resume_file, \"r\") as f:\n        last_processed = f.read().strip()\n\n# Process files\nprocessed_count = 0\nresume_found = last_processed is None  # If no resume file, start immediately\n\nfor root, _, files in os.walk(DATA_PATH):\n    for file in sorted(files):  # Sorting ensures consistent processing order\n        if file.endswith(\".wav\"):\n            input_file = os.path.join(root, file)\n            relative_path = os.path.relpath(root, DATA_PATH)  # Maintain hierarchy\n\n            if not resume_found:\n                if input_file == last_processed:\n                    resume_found = True  # Resume processing from the next file\n                continue\n\n            # Apply compression for each bitrate\n            for bitrate_label, bitrate_value in BITRATES.items():\n                output_dir = os.path.join(OUTPUT_PATH, f\"usgov_compressed_{bitrate_label}\", relative_path)\n                os.makedirs(output_dir, exist_ok=True)  # Create directories if missing\n\n                output_file = os.path.join(output_dir, file.replace(\".wav\", \".opus\"))\n                compress_audio(input_file, output_file, bitrate_value)\n\n            processed_count += 1\n\n            # Stop after compressing 150 files\n            if processed_count >= 150:\n                break\n\n            # Save progress every 50 files\n            if processed_count % 50 == 0:\n                with open(resume_file, \"w\") as f:\n                    f.write(input_file)\n                \n                # Zip and upload files every 50 processed\n                zip_path = \"/kaggle/working/usgov_compressed_speech.zip\"\n                shutil.make_archive(zip_path.replace(\".zip\", \"\"), 'zip', OUTPUT_PATH)\n                print(\"‚úÖ 50 files compressed & backup saved!\")\n\nprint(\"‚úÖ US-GOV speech compression complete!\")\n\n# Final dataset backup\nfinal_zip_path = \"/kaggle/working/usgov_compressed_speech_final.zip\"\nshutil.make_archive(final_zip_path.replace(\".zip\", \"\"), 'zip', OUTPUT_PATH)\nprint(f\"‚úÖ Final backup saved at: {final_zip_path}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T17:20:34.011619Z","iopub.execute_input":"2025-04-01T17:20:34.011946Z","iopub.status.idle":"2025-04-01T18:22:19.139096Z","shell.execute_reply.started":"2025-04-01T17:20:34.011919Z","shell.execute_reply":"2025-04-01T18:22:19.137902Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Step 4: Analyzing the speech signal quality before and after compression using SNR\n","metadata":{}},{"cell_type":"code","source":"pip install pystoi\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T04:09:51.946742Z","iopub.execute_input":"2025-04-05T04:09:51.947124Z","iopub.status.idle":"2025-04-05T04:09:55.518647Z","shell.execute_reply.started":"2025-04-05T04:09:51.947096Z","shell.execute_reply":"2025-04-05T04:09:55.517718Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#analyzing using SNR,SDR,STOI and PESQ for librivox data of 3kbps\n\nimport os\nimport librosa\nimport numpy as np\nfrom pesq import pesq\nfrom pystoi import stoi\nfrom mir_eval.separation import bss_eval_sources\n\n# === Constants ===\nSAMPLE_RATE = 16000\nDURATION = 30\nTARGET_SAMPLES = SAMPLE_RATE * DURATION\n\n# === Evaluation Functions ===\ndef fix_length(audio, target_len):\n    if len(audio) > target_len:\n        return audio[:target_len]\n    return np.pad(audio, (0, target_len - len(audio)))\n\ndef snr(original, compressed):\n    min_len = min(len(original), len(compressed))\n    original = original[:min_len]\n    compressed = compressed[:min_len]\n    noise = original - compressed\n    eps = 1e-10\n    return 10 * np.log10(np.sum(original ** 2) / (np.sum(noise ** 2) + eps))\n\n# === Paths ===\nORIGINAL_PATH = \"/kaggle/input/musan-data/musan/speech/librivox\"\nCOMPRESSED_PATH = \"/kaggle/input/compressed-data/compressed_musan/speech/librivox/compressed_3kbps/librivox\"\n\n# === Metric Storage ===\nsnr_values, sdr_values, stoi_values, pesq_values = [], [], [], []\n\n# === Evaluation Loop ===\nfor root, _, files in os.walk(ORIGINAL_PATH):\n    for file in sorted(files):\n        if file.endswith(\".wav\"):\n            original_file = os.path.join(root, file)\n            compressed_file = os.path.join(COMPRESSED_PATH, file.replace(\".wav\", \".opus\"))\n\n            try:\n                orig_audio, _ = librosa.load(original_file, sr=SAMPLE_RATE)\n                comp_audio, _ = librosa.load(compressed_file, sr=SAMPLE_RATE)\n\n                orig_audio = fix_length(orig_audio, TARGET_SAMPLES)\n                comp_audio = fix_length(comp_audio, TARGET_SAMPLES)\n\n                # SNR\n                snr_values.append(snr(orig_audio, comp_audio))\n\n                # SDR\n                sdr, _, _, _ = bss_eval_sources(orig_audio[None, :], comp_audio[None, :])\n                sdr_values.append(sdr[0])\n\n                # STOI\n                stoi_values.append(stoi(orig_audio, comp_audio, SAMPLE_RATE, extended=False))\n\n                # PESQ\n                pesq_score = pesq(SAMPLE_RATE, orig_audio, comp_audio, 'wb')\n                pesq_values.append(pesq_score)\n\n                print(f\"‚úÖ {file}: SNR={snr_values[-1]:.2f}, SDR={sdr[0]:.2f}, STOI={stoi_values[-1]:.3f}, PESQ={pesq_score:.3f}\")\n\n            except Exception as e:\n                print(f\"‚ö†Ô∏è Error processing {file}: {e}\")\n\n# === Print Averages ===\nif snr_values:\n    print(\"\\nüìä Compressed Audio Evaluation (vs Original):\")\n    print(f\"‚úÖ Avg SNR :  {np.mean(snr_values):.2f} dB\")\n    print(f\"‚úÖ Avg SDR :  {np.mean(sdr_values):.2f} dB\")\n    print(f\"‚úÖ Avg STOI:  {np.mean(stoi_values):.3f}\")\n    print(f\"‚úÖ Avg PESQ:  {np.mean(pesq_values):.3f}\")\nelse:\n    print(\"\\n‚ö† No valid files processed for metric calculation.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T06:55:16.537033Z","iopub.execute_input":"2025-04-05T06:55:16.537381Z","iopub.status.idle":"2025-04-05T07:00:28.846112Z","shell.execute_reply.started":"2025-04-05T06:55:16.537358Z","shell.execute_reply":"2025-04-05T07:00:28.845266Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#analyzing using SNR librivox data of 12kbps\n\n\nimport os\nimport librosa\nimport numpy as np\n\n# Function to compute SNR\ndef snr(original, compressed):\n    min_len = min(len(original), len(compressed))\n    original = original[:min_len]\n    compressed = compressed[:min_len]\n    \n    noise = original - compressed\n    eps = 1e-10  # Small value to prevent division by zero\n    \n    return 10 * np.log10(np.sum(original ** 2) / (np.sum(noise ** 2) + eps))\n\n# Paths\nORIGINAL_PATH = \"/kaggle/input/musan-data/musan/speech/librivox\"\nCOMPRESSED_PATH = \"/kaggle/input/compressed-data/compressed_musan/speech/librivox/compressed_12kbps/librivox\"\n\n# List to store SNR values\nsnr_values = []\n\n# Process all files for SNR evaluation\nfor root, _, files in os.walk(ORIGINAL_PATH):\n    for file in sorted(files):\n        if file.endswith(\".wav\"):\n            original_file = os.path.join(root, file)\n            compressed_file = os.path.join(COMPRESSED_PATH, file.replace(\".wav\", \".opus\"))\n            \n            # Load original and compressed audio\n            try:\n                original_audio, _ = librosa.load(original_file, sr=16000)  # Standard sampling rate\n                compressed_audio, _ = librosa.load(compressed_file, sr=16000)\n                \n                # Compute SNR\n                snr_value = snr(original_audio, compressed_audio)\n                snr_values.append(snr_value)\n                \n                print(f\"SNR for {file}: {snr_value:.2f} dB\")\n            except Exception as e:\n                print(f\"Error processing {file}: {e}\")\n\n# Compute and print the average SNR\nif snr_values:\n    avg_snr = np.mean(snr_values)\n    print(f\"\\n‚úÖ Average SNR for compressed dataset: {avg_snr:.2f} dB\")\nelse:\n    print(\"\\n‚ö† No valid files processed for SNR calculation.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T15:35:16.074063Z","iopub.execute_input":"2025-04-02T15:35:16.074461Z","iopub.status.idle":"2025-04-02T15:39:12.684789Z","shell.execute_reply.started":"2025-04-02T15:35:16.074406Z","shell.execute_reply":"2025-04-02T15:39:12.683773Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#analyzing using SNR,SDR,STOI and PESQ for librivox data of 12kbps\n\nimport os\nimport librosa\nimport numpy as np\nfrom pesq import pesq\nfrom pystoi import stoi\nfrom mir_eval.separation import bss_eval_sources\n\n# === Constants ===\nSAMPLE_RATE = 16000\nDURATION = 30\nTARGET_SAMPLES = SAMPLE_RATE * DURATION\n\n# === Evaluation Functions ===\ndef fix_length(audio, target_len):\n    if len(audio) > target_len:\n        return audio[:target_len]\n    return np.pad(audio, (0, target_len - len(audio)))\n\ndef snr(original, compressed):\n    min_len = min(len(original), len(compressed))\n    original = original[:min_len]\n    compressed = compressed[:min_len]\n    noise = original - compressed\n    eps = 1e-10\n    return 10 * np.log10(np.sum(original ** 2) / (np.sum(noise ** 2) + eps))\n\n# === Paths ===\nORIGINAL_PATH = \"/kaggle/input/musan-data/musan/speech/librivox\"\nCOMPRESSED_PATH = \"/kaggle/input/compressed-data/compressed_musan/speech/librivox/compressed_12kbps/librivox\"\n\n# === Metric Storage ===\nsnr_values, sdr_values, stoi_values, pesq_values = [], [], [], []\n\n# === Evaluation Loop ===\nfor root, _, files in os.walk(ORIGINAL_PATH):\n    for file in sorted(files):\n        if file.endswith(\".wav\"):\n            original_file = os.path.join(root, file)\n            compressed_file = os.path.join(COMPRESSED_PATH, file.replace(\".wav\", \".opus\"))\n\n            try:\n                orig_audio, _ = librosa.load(original_file, sr=SAMPLE_RATE)\n                comp_audio, _ = librosa.load(compressed_file, sr=SAMPLE_RATE)\n\n                orig_audio = fix_length(orig_audio, TARGET_SAMPLES)\n                comp_audio = fix_length(comp_audio, TARGET_SAMPLES)\n\n                # SNR\n                snr_values.append(snr(orig_audio, comp_audio))\n\n                # SDR\n                sdr, _, _, _ = bss_eval_sources(orig_audio[None, :], comp_audio[None, :])\n                sdr_values.append(sdr[0])\n\n                # STOI\n                stoi_values.append(stoi(orig_audio, comp_audio, SAMPLE_RATE, extended=False))\n\n                # PESQ\n                pesq_score = pesq(SAMPLE_RATE, orig_audio, comp_audio, 'wb')\n                pesq_values.append(pesq_score)\n\n                print(f\"‚úÖ {file}: SNR={snr_values[-1]:.2f}, SDR={sdr[0]:.2f}, STOI={stoi_values[-1]:.3f}, PESQ={pesq_score:.3f}\")\n\n            except Exception as e:\n                print(f\"‚ö†Ô∏è Error processing {file}: {e}\")\n\n# === Print Averages ===\nif snr_values:\n    print(\"\\nüìä Compressed Audio Evaluation (vs Original):\")\n    print(f\"‚úÖ Avg SNR :  {np.mean(snr_values):.2f} dB\")\n    print(f\"‚úÖ Avg SDR :  {np.mean(sdr_values):.2f} dB\")\n    print(f\"‚úÖ Avg STOI:  {np.mean(stoi_values):.3f}\")\n    print(f\"‚úÖ Avg PESQ:  {np.mean(pesq_values):.3f}\")\nelse:\n    print(\"\\n‚ö† No valid files processed for metric calculation.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T07:16:46.243324Z","iopub.execute_input":"2025-04-05T07:16:46.243652Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#analyzing using SNR for us-gov data of 12kbps\n\n\nimport os\nimport librosa\nimport numpy as np\n\n# Function to compute SNR\ndef snr(original, compressed):\n    min_len = min(len(original), len(compressed))\n    original = original[:min_len]\n    compressed = compressed[:min_len]\n    \n    noise = original - compressed\n    eps = 1e-10  # Small value to prevent division by zero\n    \n    return 10 * np.log10(np.sum(original ** 2) / (np.sum(noise ** 2) + eps))\n\n# Paths\nORIGINAL_PATH = \"/kaggle/input/musan-data/musan/speech/us-gov\"\nCOMPRESSED_PATH = \"/kaggle/input/compressed-data/compressed_musan/speech/us-gov/usgov_compressed_12kbps\"\n\n# List to store SNR values\nsnr_values = []\nfile_count = 0\nMAX_FILES = 150  # Limit to first 150 files\n\n# Process files for SNR evaluation\nfor root, _, files in os.walk(ORIGINAL_PATH):\n    for file in sorted(files):\n        if file.endswith(\".wav\"):\n            if file_count >= MAX_FILES:\n                break  # Stop after processing 150 files\n            \n            original_file = os.path.join(root, file)\n            compressed_file = os.path.join(COMPRESSED_PATH, file.replace(\".wav\", \".opus\"))\n            \n            # Load original and compressed audio\n            try:\n                original_audio, _ = librosa.load(original_file, sr=16000)  # Standard sampling rate\n                compressed_audio, _ = librosa.load(compressed_file, sr=16000)\n                \n                # Compute SNR\n                snr_value = snr(original_audio, compressed_audio)\n                snr_values.append(snr_value)\n                \n                print(f\"SNR for {file}: {snr_value:.2f} dB\")\n                file_count += 1\n            except Exception as e:\n                print(f\"Error processing {file}: {e}\")\n\n# Compute and print the average SNR\nif snr_values:\n    avg_snr = np.mean(snr_values)\n    print(f\"\\n‚úÖ Average SNR for compressed dataset (first {MAX_FILES} files): {avg_snr:.2f} dB\")\nelse:\n    print(\"\\n‚ö† No valid files processed for SNR calculation.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T09:43:48.880263Z","iopub.execute_input":"2025-04-04T09:43:48.880497Z","iopub.status.idle":"2025-04-04T09:48:07.059730Z","shell.execute_reply.started":"2025-04-04T09:43:48.880475Z","shell.execute_reply":"2025-04-04T09:48:07.058492Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#analyzing using SNR,SDR,STOI and PESQ for us-gov data of 12kbps\n\n\nimport os\nimport librosa\nimport numpy as np\nfrom pesq import pesq\nfrom pystoi import stoi\nfrom mir_eval.separation import bss_eval_sources\n\n# === Constants ===\nSAMPLE_RATE = 16000\nDURATION = 30\nTARGET_SAMPLES = SAMPLE_RATE * DURATION\n\n# === Evaluation Functions ===\ndef fix_length(audio, target_len):\n    if len(audio) > target_len:\n        return audio[:target_len]\n    return np.pad(audio, (0, target_len - len(audio)))\n\ndef snr(original, compressed):\n    min_len = min(len(original), len(compressed))\n    original = original[:min_len]\n    compressed = compressed[:min_len]\n    noise = original - compressed\n    eps = 1e-10\n    return 10 * np.log10(np.sum(original ** 2) / (np.sum(noise ** 2) + eps))\n\n# === Paths ===\nORIGINAL_PATH = \"/kaggle/input/musan-data/musan/speech/us-gov\"\nCOMPRESSED_PATH = \"/kaggle/input/compressed-data/compressed_musan/speech/us-gov/usgov_compressed_12kbps\"\n\n# === Metric Storage ===\nsnr_values, sdr_values, stoi_values, pesq_values = [], [], [], []\n\n# === Evaluation Loop ===\nfor root, _, files in os.walk(ORIGINAL_PATH):\n    for file in sorted(files):\n        if file.endswith(\".wav\"):\n            original_file = os.path.join(root, file)\n            compressed_file = os.path.join(COMPRESSED_PATH, file.replace(\".wav\", \".opus\"))\n\n            try:\n                orig_audio, _ = librosa.load(original_file, sr=SAMPLE_RATE)\n                comp_audio, _ = librosa.load(compressed_file, sr=SAMPLE_RATE)\n\n                orig_audio = fix_length(orig_audio, TARGET_SAMPLES)\n                comp_audio = fix_length(comp_audio, TARGET_SAMPLES)\n\n                # SNR\n                snr_values.append(snr(orig_audio, comp_audio))\n\n                # SDR\n                sdr, _, _, _ = bss_eval_sources(orig_audio[None, :], comp_audio[None, :])\n                sdr_values.append(sdr[0])\n\n                # STOI\n                stoi_values.append(stoi(orig_audio, comp_audio, SAMPLE_RATE, extended=False))\n\n                # PESQ\n                pesq_score = pesq(SAMPLE_RATE, orig_audio, comp_audio, 'wb')\n                pesq_values.append(pesq_score)\n\n                print(f\"‚úÖ {file}: SNR={snr_values[-1]:.2f}, SDR={sdr[0]:.2f}, STOI={stoi_values[-1]:.3f}, PESQ={pesq_score:.3f}\")\n\n            except Exception as e:\n                print(f\"‚ö†Ô∏è Error processing {file}: {e}\")\n\n# === Print Averages ===\nif snr_values:\n    print(\"\\nüìä Compressed Audio Evaluation (vs Original):\")\n    print(f\"‚úÖ Avg SNR :  {np.mean(snr_values):.2f} dB\")\n    print(f\"‚úÖ Avg SDR :  {np.mean(sdr_values):.2f} dB\")\n    print(f\"‚úÖ Avg STOI:  {np.mean(stoi_values):.3f}\")\n    print(f\"‚úÖ Avg PESQ:  {np.mean(pesq_values):.3f}\")\nelse:\n    print(\"\\n‚ö† No valid files processed for metric calculation.\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#analyzing using SNR for us-gov data of 3kbps\n\n\nimport os\nimport librosa\nimport numpy as np\n\n# Function to compute SNR\ndef snr(original, compressed):\n    min_len = min(len(original), len(compressed))\n    original = original[:min_len]\n    compressed = compressed[:min_len]\n    \n    noise = original - compressed\n    eps = 1e-10  # Small value to prevent division by zero\n    \n    return 10 * np.log10(np.sum(original ** 2) / (np.sum(noise ** 2) + eps))\n\n# Paths\nORIGINAL_PATH = \"/kaggle/input/musan-data/musan/speech/us-gov\"\nCOMPRESSED_PATH = \"/kaggle/input/compressed-data/compressed_musan/speech/us-gov/usgov_compressed_3kbps\"\n\n# List to store SNR values\nsnr_values = []\nfile_count = 0\nMAX_FILES = 150  # Limit to first 150 files\n\n# Process files for SNR evaluation\nfor root, _, files in os.walk(ORIGINAL_PATH):\n    for file in sorted(files):\n        if file.endswith(\".wav\"):\n            if file_count >= MAX_FILES:\n                break  # Stop after processing 150 files\n            \n            original_file = os.path.join(root, file)\n            compressed_file = os.path.join(COMPRESSED_PATH, file.replace(\".wav\", \".opus\"))\n            \n            # Load original and compressed audio\n            try:\n                original_audio, _ = librosa.load(original_file, sr=16000)  # Standard sampling rate\n                compressed_audio, _ = librosa.load(compressed_file, sr=16000)\n                \n                # Compute SNR\n                snr_value = snr(original_audio, compressed_audio)\n                snr_values.append(snr_value)\n                \n                print(f\"SNR for {file}: {snr_value:.2f} dB\")\n                file_count += 1\n            except Exception as e:\n                print(f\"Error processing {file}: {e}\")\n\n# Compute and print the average SNR\nif snr_values:\n    avg_snr = np.mean(snr_values)\n    print(f\"\\n‚úÖ Average SNR for compressed dataset (first {MAX_FILES} files): {avg_snr:.2f} dB\")\nelse:\n    print(\"\\n‚ö† No valid files processed for SNR calculation.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T09:50:37.319907Z","iopub.execute_input":"2025-04-04T09:50:37.320297Z","iopub.status.idle":"2025-04-04T09:52:51.211660Z","shell.execute_reply.started":"2025-04-04T09:50:37.320267Z","shell.execute_reply":"2025-04-04T09:52:51.210420Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#analyzing using SNR,SDR,STOI and PESQ for us-gov data of 3kbps\n\n\nimport os\nimport librosa\nimport numpy as np\nfrom pesq import pesq\nfrom pystoi import stoi\nfrom mir_eval.separation import bss_eval_sources\n\n# === Constants ===\nSAMPLE_RATE = 16000\nDURATION = 30\nTARGET_SAMPLES = SAMPLE_RATE * DURATION\n\n# === Evaluation Functions ===\ndef fix_length(audio, target_len):\n    if len(audio) > target_len:\n        return audio[:target_len] #trim if audio is longer than 30secs\n    return np.pad(audio, (0, target_len - len(audio))) #pad with 0s if shorter\n\ndef snr(original, compressed):\n    min_len = min(len(original), len(compressed))\n    original = original[:min_len]\n    compressed = compressed[:min_len]\n    noise = original - compressed\n    eps = 1e-10 #uses a small eps to avoid div by 0 error\n    return 10 * np.log10(np.sum(original ** 2) / (np.sum(noise ** 2) + eps))\n\n# === Paths ===\nORIGINAL_PATH = \"/kaggle/input/musan-data/musan/speech/us-gov\"\nCOMPRESSED_PATH = \"/kaggle/input/compressed-data/compressed_musan/speech/us-gov/usgov_compressed_3kbps\"\n\n# === Metric Storage ===\nsnr_values, sdr_values, stoi_values, pesq_values = [], [], [], []\n\n# === Evaluation Loop ===\nfor root, _, files in os.walk(ORIGINAL_PATH):\n    for file in sorted(files):\n        if file.endswith(\".wav\"):\n            original_file = os.path.join(root, file)\n            compressed_file = os.path.join(COMPRESSED_PATH, file.replace(\".wav\", \".opus\"))\n\n            try:\n                orig_audio, _ = librosa.load(original_file, sr=SAMPLE_RATE)\n                comp_audio, _ = librosa.load(compressed_file, sr=SAMPLE_RATE)\n\n                orig_audio = fix_length(orig_audio, TARGET_SAMPLES)\n                comp_audio = fix_length(comp_audio, TARGET_SAMPLES)\n\n                # SNR\n                # a measure of the strength\n                #of the desired signal relative to background noise (undesired signal).\n                snr_values.append(snr(orig_audio, comp_audio))\n\n                # SDR\n                sdr, _, _, _ = bss_eval_sources(orig_audio[None, :], comp_audio[None, :])\n                sdr_values.append(sdr[0])\n\n                # STOI\n                stoi_values.append(stoi(orig_audio, comp_audio, SAMPLE_RATE, extended=False))\n\n                # PESQ\n                pesq_score = pesq(SAMPLE_RATE, orig_audio, comp_audio, 'wb')\n                pesq_values.append(pesq_score)\n\n                print(f\"‚úÖ {file}: SNR={snr_values[-1]:.2f}, SDR={sdr[0]:.2f}, STOI={stoi_values[-1]:.3f}, PESQ={pesq_score:.3f}\")\n\n            except Exception as e:\n                print(f\"‚ö†Ô∏è Error processing {file}: {e}\")\n\n# === Print Averages ===\nif snr_values:\n    print(\"\\nüìä Compressed Audio Evaluation (vs Original):\")\n    print(f\"‚úÖ Avg SNR :  {np.mean(snr_values):.2f} dB\")\n    print(f\"‚úÖ Avg SDR :  {np.mean(sdr_values):.2f} dB\")\n    print(f\"‚úÖ Avg STOI:  {np.mean(stoi_values):.3f}\")\n    print(f\"‚úÖ Avg PESQ:  {np.mean(pesq_values):.3f}\")\nelse:\n    print(\"\\n‚ö† No valid files processed for metric calculation.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T08:44:33.126678Z","iopub.execute_input":"2025-04-05T08:44:33.127134Z","iopub.status.idle":"2025-04-05T08:50:40.612278Z","shell.execute_reply.started":"2025-04-05T08:44:33.127098Z","shell.execute_reply":"2025-04-05T08:50:40.611356Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":">**SNR :** How much useful signal is present relative to noise.\n        It's a basic, energy-based metric.\n> Basic comparison of energy differences between signals\n  Quick check of degradation in systems like audio compression\n> Higher SNR --> Better quality\n>\n> **SDR :** Used mainly in source separation tasks\n> Measures how much of the desired signal is preserved vs distortion (including artifacts, interference, and noise)\n>  It Decomposes:\n> estimated signal = true source + distortion + artifacts\n  So, SDR captures more nuanced errors than SNR\n> Interpretation:\nHigher SDR = better reconstruction/separation\nAccounts for perceptual quality, not just energy\nOften used in blind source separation (BSS) and enhancement tasks","metadata":{}},{"cell_type":"markdown","source":"# Step 5: Aligning Original and compressed pairs for training the model","metadata":{}},{"cell_type":"code","source":"import os\nimport librosa\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\n#PyTorch's torch.utils.data.Dataset is an abstract class that \n#helps you define how your data is structured and how to retrieve it.\n\n# Define paths\nORIGINAL_SPEECH_PATH = \"/kaggle/input/musan-data/musan/speech\"\nCOMPRESSED_SPEECH_PATH = \"/kaggle/input/compressed-data/compressed_musan/speech\"\nBITRATES = [\"3kbps\", \"6kbps\", \"12kbps\"]\nSUBSETS = [\"librivox\", \"us-gov\"]\nUS_GOV_COMPRESSED_LIMIT = 150  # Only first 150 files are compressed\n\n#custom dataset class\n#Here, we are dealing with pairs of data (original, compressed) that are in different loc, needs to be\n#to be loaded as pairs, formated as tensors and passed for training in a structured way\nclass SpeechDataset(Dataset):\n    #nitializes dataset parameters.\n    def __init__(self, original_path, compressed_path, bitrates, subsets, sr=16000):\n        self.original_path = original_path\n        self.compressed_path = compressed_path\n        self.bitrates = bitrates\n        self.subsets = subsets\n        self.sr = sr\n        self.file_pairs = self._get_file_pairs()\n        \n        if len(self.file_pairs) == 0:\n            raise ValueError(\"‚ùå No matching file pairs found! Check your paths.\")\n\n    def _get_file_pairs(self):\n        file_pairs = []\n        for subset in self.subsets:\n            subset_path = os.path.join(self.original_path, subset)\n            file_list = sorted([f for f in os.listdir(subset_path) if f.endswith(\".wav\")])\n\n            if subset == \"us-gov\":\n                file_list = file_list[:US_GOV_COMPRESSED_LIMIT]  # Limit to 150 files\n\n            for file in file_list:\n                original_file = os.path.join(subset_path, file)\n\n                for bitrate in self.bitrates:\n                    if subset == \"librivox\":\n                        compressed_file = os.path.join(\n                            self.compressed_path, subset, f\"compressed_{bitrate}\", subset, file.replace(\".wav\", \".opus\")\n                        )\n                    elif subset == \"us-gov\":\n                        compressed_file = os.path.join(\n                            self.compressed_path, subset, f\"usgov_compressed_{bitrate}\", file.replace(\".wav\", \".opus\")\n                        )\n\n                    if os.path.exists(compressed_file):\n                        file_pairs.append((original_file, compressed_file))\n                        #Validates that both original and compressed files exist before adding them.\n                    else:\n                        print(f\"‚ùå Missing file: {compressed_file}\")  # Debugging output\n                \n        return file_pairs\n\n    def __len__(self):\n        return len(self.file_pairs)\n\n    def __getitem__(self, idx):\n        orig_file, comp_file = self.file_pairs[idx]\n        #Loads both original and compressed audio at 16 kHz.\n        orig_audio, _ = librosa.load(orig_file, sr=self.sr)\n        comp_audio, _ = librosa.load(comp_file, sr=self.sr)\n\n        #Wraps them as PyTorch tensors with shape (1, samples) (mono channel).\n        # ‚úÖ Ensure correct format (channels, samples) ‚Üí (1, samples)\n        orig_audio = torch.tensor(orig_audio).unsqueeze(0)  # (1, samples)\n        comp_audio = torch.tensor(comp_audio).unsqueeze(0)  # (1, samples)\n\n        return orig_audio, comp_audio\n\n# Collate function to pad all audio to the longest sample in the batch\ndef collate_fn(batch):\n    orig_batch, comp_batch = zip(*batch)\n    \n    max_len = max(max(x.shape[1] for x in orig_batch), max(x.shape[1] for x in comp_batch))\n    \n    def pad_audio(audio):\n        return torch.nn.functional.pad(audio, (0, max_len - audio.shape[1]))\n    #batches the data\n    orig_batch = torch.stack([pad_audio(x) for x in orig_batch])  # (batch, 1, samples)\n    comp_batch = torch.stack([pad_audio(x) for x in comp_batch])  # (batch, 1, samples)\n    #Converts list of tensors to a single batch tensor of shape: (batch_size, 1, samples)\n    return orig_batch, comp_batch\n\n# ‚úÖ Load dataset into DataLoader\n# DataLoader makes reading files easier, batches the data, randomly shuffles it, pads non-uniform data using collate func\n\ndataset = SpeechDataset(ORIGINAL_SPEECH_PATH, COMPRESSED_SPEECH_PATH, BITRATES, SUBSETS)\ndataloader = DataLoader(dataset, batch_size=4, shuffle=True, collate_fn=collate_fn)\n\n# ‚úÖ Check dataset loading\nfor orig, comp in dataloader:\n    print(f\"‚úÖ After Fix - Original Shape: {orig.shape}, Compressed Shape: {comp.shape}\")\n    break  # Only check the first batch\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T15:09:08.529827Z","iopub.execute_input":"2025-04-04T15:09:08.530499Z","iopub.status.idle":"2025-04-04T15:09:13.366796Z","shell.execute_reply.started":"2025-04-04T15:09:08.530445Z","shell.execute_reply":"2025-04-04T15:09:13.365812Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Step 6 : Model Training using demucs","metadata":{}},{"cell_type":"code","source":"!pip install -q demucs\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T12:53:01.346129Z","iopub.execute_input":"2025-04-06T12:53:01.346561Z","iopub.status.idle":"2025-04-06T12:53:21.559076Z","shell.execute_reply.started":"2025-04-06T12:53:01.346506Z","shell.execute_reply":"2025-04-06T12:53:21.557609Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install -q demucs\nimport os\nimport librosa\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom demucs.hdemucs import HDemucs  # Corrected import\n\n# ‚úÖ Ensure GPU Usage\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"üî• Using device: {device}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T05:22:54.497011Z","iopub.execute_input":"2025-04-05T05:22:54.497303Z","iopub.status.idle":"2025-04-05T05:22:57.976162Z","shell.execute_reply.started":"2025-04-05T05:22:54.497282Z","shell.execute_reply":"2025-04-05T05:22:57.974968Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Paths\nORIGINAL_SPEECH_PATH = \"/kaggle/input/musan-data/musan/speech\"\nCOMPRESSED_SPEECH_PATH = \"/kaggle/input/compressed-data/compressed_musan/speech\"\nBITRATES = [\"3kbps\", \"6kbps\", \"12kbps\"]\nSUBSETS = [\"librivox\", \"us-gov\"]\nSAMPLE_RATE = 16000\nDURATION = 30  # 30 seconds\nTARGET_SAMPLES = SAMPLE_RATE * DURATION\n\nclass SpeechDataset(Dataset):\n    def __init__(self, original_path, compressed_path, bitrates, subsets, sr=SAMPLE_RATE):\n        self.original_path = original_path\n        self.compressed_path = compressed_path\n        self.bitrates = bitrates\n        self.subsets = subsets\n        self.sr = sr\n        self.file_pairs = self._get_file_pairs()\n        \n        if len(self.file_pairs) == 0:\n            raise ValueError(\"‚ùå No matching file pairs found! Check your paths.\")\n\n    def _get_file_pairs(self):\n        file_pairs = []\n        for subset in self.subsets:\n            subset_path = os.path.join(self.original_path, subset)\n            file_list = sorted([f for f in os.listdir(subset_path) if f.endswith(\".wav\")])\n\n            for file in file_list:\n                original_file = os.path.join(subset_path, file)\n\n                for bitrate in self.bitrates:\n                    compressed_file = os.path.join(\n                        self.compressed_path, subset, f\"compressed_{bitrate}\", subset, file.replace(\".wav\", \".opus\")\n                    )\n\n                    if os.path.exists(compressed_file):\n                        file_pairs.append((original_file, compressed_file))\n                \n        return file_pairs\n\n    def _load_audio(self, path):\n        audio, _ = librosa.load(path, sr=self.sr, mono=True)\n        if len(audio) > TARGET_SAMPLES:\n            audio = audio[:TARGET_SAMPLES]\n        else:\n            audio = F.pad(torch.tensor(audio), (0, TARGET_SAMPLES - len(audio)))\n        return audio\n\n    def __len__(self):\n        return len(self.file_pairs)\n\n    def __getitem__(self, idx):\n        orig_file, comp_file = self.file_pairs[idx]\n        orig_audio = self._load_audio(orig_file)\n        comp_audio = self._load_audio(comp_file)\n        return orig_audio, comp_audio\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T16:52:57.304277Z","iopub.execute_input":"2025-04-04T16:52:57.304592Z","iopub.status.idle":"2025-04-04T16:52:57.312824Z","shell.execute_reply.started":"2025-04-04T16:52:57.304567Z","shell.execute_reply":"2025-04-04T16:52:57.311834Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\n\ndef collate_fn(batch):\n    orig_batch, comp_batch = zip(*batch)  # Unpack pairs\n\n    #Converts each 1D audio tensor to stereo (2 channels) by duplicating it\n    def stereo(audio):\n        audio = torch.tensor(audio, dtype=torch.float32)  # ‚úÖ Convert NumPy to Tensor\n        return torch.stack([audio, audio], dim=0)  # Duplicate mono signal to stereo\n    #Finally stacks into batch tensors\n    orig_batch = torch.stack([stereo(x) for x in orig_batch])  # (B, 2, T)\n    comp_batch = torch.stack([stereo(x) for x in comp_batch])  # (B, 2, T)\n\n    return orig_batch, comp_batch\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T16:58:01.570807Z","iopub.execute_input":"2025-04-04T16:58:01.571217Z","iopub.status.idle":"2025-04-04T16:58:01.576245Z","shell.execute_reply.started":"2025-04-04T16:58:01.571187Z","shell.execute_reply":"2025-04-04T16:58:01.575477Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dataset = SpeechDataset(ORIGINAL_SPEECH_PATH, COMPRESSED_SPEECH_PATH, BITRATES, SUBSETS)\ndataloader = DataLoader(dataset, batch_size=4, shuffle=True, collate_fn=collate_fn)\n\nprint(f\"‚úÖ Loaded {len(dataset)} audio pairs\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T16:58:07.178594Z","iopub.execute_input":"2025-04-04T16:58:07.178938Z","iopub.status.idle":"2025-04-04T16:58:07.485931Z","shell.execute_reply.started":"2025-04-04T16:58:07.178909Z","shell.execute_reply":"2025-04-04T16:58:07.485082Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = HDemucs(sources=[\"speech\"]).to(device)  # Load pretrained Demucs\noptimizer = optim.Adam(model.parameters(), lr=1e-4)\nloss_fn = nn.MSELoss()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T16:58:24.129819Z","iopub.execute_input":"2025-04-04T16:58:24.130087Z","iopub.status.idle":"2025-04-04T16:58:24.971972Z","shell.execute_reply.started":"2025-04-04T16:58:24.130041Z","shell.execute_reply":"2025-04-04T16:58:24.971321Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"EPOCHS = 10  # Adjust as needed\n\nfor epoch in range(EPOCHS):\n    total_loss = 0\n    model.train()\n    \n    for orig_wave, comp_wave in dataloader:\n        orig_wave, comp_wave = orig_wave.to(device), comp_wave.to(device)\n\n        optimizer.zero_grad()\n        enhanced_wave = model(comp_wave)  # Demucs predicts clean audio\n\n        #  Match shape with target - some models return output with shape (B, 1, 2, T) ‚Äî extra dim.\n        #This fixes it to standard shape (B, 2, T).\n        if enhanced_wave.ndim == 4:\n            enhanced_wave = enhanced_wave.squeeze(1)  # From (B,1,2,T) ‚Üí (B,2,T)\n\n        #  Sanity check- ensures output matches with target\n        assert enhanced_wave.shape == orig_wave.shape, \\\n            f\"Shape mismatch: got {enhanced_wave.shape}, expected {orig_wave.shape}\"\n\n        loss = loss_fn(enhanced_wave, orig_wave)# calc mse\n\n        loss.backward() #gradient computation\n        optimizer.step()#weight update\n        total_loss += loss.item()\n\n    print(f\"üì¢ Epoch {epoch+1}/{EPOCHS}, Loss: {total_loss / len(dataloader):.6f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T17:11:32.050193Z","iopub.execute_input":"2025-04-04T17:11:32.050517Z","iopub.status.idle":"2025-04-04T18:37:13.409495Z","shell.execute_reply.started":"2025-04-04T17:11:32.050493Z","shell.execute_reply":"2025-04-04T18:37:13.407506Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"> ## Training was stopped forcefully since it was taking longer than expected to complete 10 epochs  ","metadata":{}},{"cell_type":"code","source":"\ntorch.save(model.state_dict(), \"demucs_epoch_8.pth\")\n# retrieves the current state of the model ‚Äî this includes all learnable parameters \n#(weights, biases, etc.) at that point in training.\nprint(\"‚úÖ Model saved successfully!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T18:37:24.646880Z","iopub.execute_input":"2025-04-04T18:37:24.647196Z","iopub.status.idle":"2025-04-04T18:37:25.166674Z","shell.execute_reply.started":"2025-04-04T18:37:24.647173Z","shell.execute_reply":"2025-04-04T18:37:25.165919Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Step 7: Reconstructing using the model on the unseen data","metadata":{}},{"cell_type":"code","source":"#compressing 150th - 180th file in us-gov folder which was not used for training earlier\n\nimport os\nfrom tqdm import tqdm\n\ndef compress_files(input_folder, output_folder, bitrate_kbps=6):\n    os.makedirs(output_folder, exist_ok=True)\n    files = sorted([f for f in os.listdir(input_folder) if f.endswith(\".wav\")])[150:180]  # Take only 30\n\n    for file in tqdm(files, desc=f\"Compressing to {bitrate_kbps}kbps\"):\n        input_path = os.path.join(input_folder, file)\n        output_path = os.path.join(output_folder, file.replace(\".wav\", \".opus\"))\n\n        os.system(f\"ffmpeg -y -loglevel error -i '{input_path}' -c:a libopus -b:a {bitrate_kbps}k '{output_path}'\")\n\n    return [os.path.join(output_folder, f.replace(\".wav\", \".opus\")) for f in files]\n\n# Define paths\nORIG_UNSEEN_PATH = \"/kaggle/input/musan-data/musan/speech/us-gov\"\nCOMPRESSED_TEST_PATH = \"./test_compressed/us-gov\"\n\n# Run compression\ncompressed_files = compress_files(ORIG_UNSEEN_PATH, COMPRESSED_TEST_PATH, bitrate_kbps=6)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T05:15:54.212541Z","iopub.execute_input":"2025-04-05T05:15:54.212806Z","iopub.status.idle":"2025-04-05T05:18:56.567205Z","shell.execute_reply.started":"2025-04-05T05:15:54.212785Z","shell.execute_reply":"2025-04-05T05:18:56.566427Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#reconstructing using demucs model\n\nimport os\nimport torch\nimport torchaudio\nimport torch.nn.functional as F\nfrom torchaudio.transforms import Resample\nfrom tqdm import tqdm\nfrom demucs.hdemucs import HDemucs\nimport soundfile as sf\n\n# === CONSTANTS ===\nSAMPLE_RATE = 16000\nDURATION = 30\nTARGET_SAMPLES = SAMPLE_RATE * DURATION\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# === PATHS ===\nCOMPRESSED_FOLDER = \"/kaggle/working/test_compressed/us-gov\"\nSAVE_RECONSTRUCTED = \"/kaggle/working/reconstructed_usgov_test\"\nos.makedirs(SAVE_RECONSTRUCTED, exist_ok=True)\n\n# === LOAD MODEL ===\nmodel = HDemucs(sources=[\"speech\"]).to(DEVICE)\nmodel.load_state_dict(torch.load(\"/kaggle/input/demucs_epoch_8/pytorch/default/1/demucs_epoch_8.pth\", map_location=DEVICE))\nmodel.eval()\nprint(\"‚úÖ Model loaded.\")\n\n# === HELPER FUNCTION ===\ndef prepare_input(file_path):\n    waveform, sr = torchaudio.load(file_path)  # (1, T) for mono\n    if sr != SAMPLE_RATE:\n        resampler = Resample(sr, SAMPLE_RATE)\n        waveform = resampler(waveform)\n\n    waveform = waveform.mean(dim=0)  # Ensure mono\n    if waveform.shape[0] > TARGET_SAMPLES:\n        waveform = waveform[:TARGET_SAMPLES]\n    else:\n        waveform = F.pad(waveform, (0, TARGET_SAMPLES - waveform.shape[0]))\n\n    # Convert to stereo (2, T)\n    stereo_wave = torch.stack([waveform, waveform], dim=0)\n    return stereo_wave.unsqueeze(0).to(DEVICE)  # (1, 2, T)\n\n# === SELECT FILES ===\ncompressed_files = sorted([\n    os.path.join(COMPRESSED_FOLDER, f)\n    for f in os.listdir(COMPRESSED_FOLDER)\n    if f.endswith(\".opus\")\n])[:30]  # First 30\n\n# === RECONSTRUCT LOOP ===\nfor comp_path in tqdm(compressed_files, desc=\"üîä Reconstructing\"):\n    input_tensor = prepare_input(comp_path)\n\n    with torch.no_grad():\n        output = model(input_tensor)\n\n        # Handle (B,1,2,T) if needed\n        if output.ndim == 4:\n            output = output.squeeze(1)  # (B, 2, T)\n\n        output = output.squeeze(0).cpu()  # (2, T)\n\n    # Save as (T, 2)\n    out_path = os.path.join(\n        SAVE_RECONSTRUCTED,\n        os.path.basename(comp_path).replace(\".opus\", \"_reconstructed.wav\")\n    )\n    sf.write(out_path, output.permute(1, 0).numpy(), SAMPLE_RATE)\n\nprint(\"‚úÖ Done reconstructing and saving 30 test files.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T05:38:15.116556Z","iopub.execute_input":"2025-04-05T05:38:15.116951Z","iopub.status.idle":"2025-04-05T05:39:12.804892Z","shell.execute_reply.started":"2025-04-05T05:38:15.116914Z","shell.execute_reply":"2025-04-05T05:39:12.804133Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#zipping the compressed data (prepared for testing ) and reconstructed\n#samples from the working directory\n\nimport zipfile\nimport os\n\ndef zip_folder(folder_path, zip_path):\n    with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n        for root, _, files in os.walk(folder_path):\n            for file in files:\n                full_path = os.path.join(root, file)\n                arcname = os.path.relpath(full_path, start=folder_path)\n                zipf.write(full_path, arcname=arcname)\n\n# Paths\nreconstructed_folder = \"/kaggle/working/reconstructed_usgov_test\"\ncompressed_folder = \"/kaggle/working/test_compressed\"\n\n# Output ZIP paths\nreconstructed_zip = \"/kaggle/working/reconstructed_usgov_test.zip\"\ncompressed_zip = \"/kaggle/working/test_compressed.zip\"\n\n# Zip both folders\nzip_folder(reconstructed_folder, reconstructed_zip)\nzip_folder(compressed_folder, compressed_zip)\n\nprint(\"‚úÖ Both folders zipped and saved:\")\nprint(f\"üìÅ {reconstructed_zip}\")\nprint(f\"üìÅ {compressed_zip}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T05:46:06.254029Z","iopub.execute_input":"2025-04-05T05:46:06.254328Z","iopub.status.idle":"2025-04-05T05:46:09.916429Z","shell.execute_reply.started":"2025-04-05T05:46:06.254308Z","shell.execute_reply":"2025-04-05T05:46:09.915675Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install pystoi\n!pip install pesq\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T08:40:18.650857Z","iopub.execute_input":"2025-04-05T08:40:18.651278Z","iopub.status.idle":"2025-04-05T08:40:36.904440Z","shell.execute_reply.started":"2025-04-05T08:40:18.651241Z","shell.execute_reply":"2025-04-05T08:40:36.903626Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install mir_eval\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T08:44:16.448955Z","iopub.execute_input":"2025-04-05T08:44:16.449276Z","iopub.status.idle":"2025-04-05T08:44:19.997069Z","shell.execute_reply.started":"2025-04-05T08:44:16.449254Z","shell.execute_reply":"2025-04-05T08:44:19.996169Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Step 8: Evaluating the model on STOI, SDR and PESQ","metadata":{}},{"cell_type":"code","source":"import os\nimport torch\nimport torchaudio\nfrom torchaudio.transforms import Resample\nfrom tqdm import tqdm\nfrom pesq import pesq\nfrom pystoi import stoi\nfrom mir_eval.separation import bss_eval_sources\nimport numpy as np\n\n# === CONFIG ===\nSAMPLE_RATE = 16000\nORIGINAL_PATH = \"/kaggle/input/musan-data/musan/speech/us-gov\"\nRECONSTRUCTED_PATH = \"/kaggle/working/reconstructed_usgov_test\"\n\n# === EVALUATION METRICS ===\nsdr_scores = []\nstoi_scores = []\npesq_scores = []\n\n# === FILE LIST ===\nreconstructed_files = sorted([\n    f for f in os.listdir(RECONSTRUCTED_PATH) if f.endswith(\"_reconstructed.wav\")\n])\n\nfor rec_file in tqdm(reconstructed_files, desc=\"üéß Evaluating\"):\n    # Match original\n    original_name = rec_file.replace(\"_reconstructed.wav\", \".wav\")\n    orig_path = os.path.join(ORIGINAL_PATH, original_name)\n    rec_path = os.path.join(RECONSTRUCTED_PATH, rec_file)\n\n    if not os.path.exists(orig_path):\n        print(f\"‚ùå Missing original: {original_name}\")\n        continue\n\n    # Load both files\n    orig_audio, sr1 = torchaudio.load(orig_path)\n    rec_audio, sr2 = torchaudio.load(rec_path)\n\n    # Convert to mono\n    orig_audio = orig_audio.mean(dim=0)\n    rec_audio = rec_audio.mean(dim=0)\n\n    # Resample if needed\n    if sr1 != SAMPLE_RATE:\n        orig_audio = Resample(sr1, SAMPLE_RATE)(orig_audio)\n    if sr2 != SAMPLE_RATE:\n        rec_audio = Resample(sr2, SAMPLE_RATE)(rec_audio)\n\n    # Truncate/pad to same length\n    min_len = min(orig_audio.shape[-1], rec_audio.shape[-1])\n    orig_audio = orig_audio[:min_len]\n    rec_audio = rec_audio[:min_len]\n\n    # Convert to numpy\n    orig_np = orig_audio.numpy()\n    rec_np = rec_audio.numpy()\n\n    # === Metrics ===\n    # SDR\n    sdr, _, _, _ = bss_eval_sources(orig_np[None], rec_np[None])\n    sdr_scores.append(sdr[0])\n\n    # STOI\n    stoi_val = stoi(orig_np, rec_np, SAMPLE_RATE, extended=False)\n    stoi_scores.append(stoi_val)\n\n    # PESQ\n    pesq_val = pesq(SAMPLE_RATE, orig_np, rec_np, 'wb')\n    pesq_scores.append(pesq_val)\n\n# === AVERAGES ===\nprint(\"\\nüìä Evaluation Results on 30 Files:\")\nprint(f\"‚úÖ SDR  (Signal-to-Distortion Ratio): {np.mean(sdr_scores):.2f} dB\")\nprint(f\"‚úÖ STOI (Speech Intelligibility):     {np.mean(stoi_scores):.3f}\")\nprint(f\"‚úÖ PESQ (Perceptual Quality):        {np.mean(pesq_scores):.3f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T06:20:50.357527Z","iopub.execute_input":"2025-04-05T06:20:50.357899Z","iopub.status.idle":"2025-04-05T06:21:25.461032Z","shell.execute_reply.started":"2025-04-05T06:20:50.357859Z","shell.execute_reply":"2025-04-05T06:21:25.460180Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Step 9: Test on real-world speech data\n","metadata":{}},{"cell_type":"code","source":"pip install yt-dlp\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T12:46:00.448918Z","iopub.execute_input":"2025-04-06T12:46:00.449238Z","iopub.status.idle":"2025-04-06T12:46:09.742047Z","shell.execute_reply.started":"2025-04-06T12:46:00.449210Z","shell.execute_reply":"2025-04-06T12:46:09.740674Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!yt-dlp -x --audio-format wav -o \"yt_originalTalk.%(ext)s\" https://www.youtube.com/watch?v=t2oOFs4WgI0\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T12:49:09.455166Z","iopub.execute_input":"2025-04-06T12:49:09.455565Z","iopub.status.idle":"2025-04-06T12:49:19.747909Z","shell.execute_reply.started":"2025-04-06T12:49:09.455512Z","shell.execute_reply":"2025-04-06T12:49:19.746519Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\n\n# List all .wav files in the current directory\nfor f in os.listdir():\n    if f.endswith(\".wav\"):\n        print(f)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T12:50:32.489802Z","iopub.execute_input":"2025-04-06T12:50:32.490163Z","iopub.status.idle":"2025-04-06T12:50:32.497503Z","shell.execute_reply.started":"2025-04-06T12:50:32.490133Z","shell.execute_reply":"2025-04-06T12:50:32.496136Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!apt-get install -y ffmpeg  # If not already installed\n\n# Compress to 6kbps opus\n!ffmpeg -i yt_originalTalk.wav -c:a libopus -b:a 6k yt_compressedTalk.opus\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T12:50:52.970484Z","iopub.execute_input":"2025-04-06T12:50:52.970874Z","iopub.status.idle":"2025-04-06T12:51:08.459037Z","shell.execute_reply.started":"2025-04-06T12:50:52.970843Z","shell.execute_reply":"2025-04-06T12:51:08.457685Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!ffmpeg -i yt_compressedTalk.opus -ac 1 -ar 16000 yt_compressedTalk_16k_mono.wav\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T12:52:27.516748Z","iopub.execute_input":"2025-04-06T12:52:27.517158Z","iopub.status.idle":"2025-04-06T12:52:29.557142Z","shell.execute_reply.started":"2025-04-06T12:52:27.517124Z","shell.execute_reply":"2025-04-06T12:52:29.555756Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torchaudio\nimport torch\nfrom torchaudio.transforms import Resample\nimport soundfile as sf\nfrom demucs.hdemucs import HDemucs\n\n# Load full audio\nwaveform, sr = torchaudio.load(\"yt_compressedTalk_16k_mono.wav\")\nif sr != 16000:\n    waveform = Resample(sr, 16000)(waveform)\n\n# Convert to mono if not already\nwaveform = waveform.mean(dim=0)\n\n# Convert mono to stereo\nstereo_wave = torch.stack([waveform, waveform], dim=0).unsqueeze(0).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Load model\nmodel = HDemucs(sources=[\"speech\"]).to(stereo_wave.device)\nmodel.load_state_dict(torch.load(\"/kaggle/input/demucs_epoch_8/pytorch/default/1/demucs_epoch_8.pth\", map_location=stereo_wave.device))\nmodel.eval()\n\n# Run inference\nwith torch.no_grad():\n    output = model(stereo_wave)\n    output = output.squeeze()\n\n# Save output\nsf.write(\"yt_reconstructed_full.wav\", output.permute(1, 0).cpu().numpy(), 16000)\nprint(\"‚úÖ Reconstructed audio saved as yt_reconstructed_full.wav\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T12:53:57.892267Z","iopub.execute_input":"2025-04-06T12:53:57.892657Z","iopub.status.idle":"2025-04-06T13:01:58.987144Z","shell.execute_reply.started":"2025-04-06T12:53:57.892630Z","shell.execute_reply":"2025-04-06T13:01:58.985608Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from IPython.display import Audio\n\nprint(\"Original (compressed):\")\ndisplay(Audio(\"yt_compressedTalk_16k_mono.wav\"))\n\nprint(\"Reconstructed:\")\ndisplay(Audio(\"yt_reconstructed_full.wav\"))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T13:15:25.926634Z","iopub.execute_input":"2025-04-06T13:15:25.927043Z","iopub.status.idle":"2025-04-06T13:15:28.211158Z","shell.execute_reply.started":"2025-04-06T13:15:25.927009Z","shell.execute_reply":"2025-04-06T13:15:28.209716Z"}},"outputs":[],"execution_count":null}]}